metric_name,metric_type,interval,unit_name,per_unit_name,description,orientation,integration,short_name,curated_metric
warpstream.can_connect,gauge,,,,"1 if can connect to Warpstream Agent, otherwise 0",0,warpstream,can_connect,
warpstream.agent_connection_throttle_count,count,,,,"number of new connections opened to the Warpstream Agent throttled",1,warpstream,agent_connection_throttle_count,
warpstream.agent_deadscanner_optimistic_queue_delete_file_outcome,count,,,,"incremented whenever the Warpstream Agent processed a file in its deadscanner optimistic queue, tagged by 'outcome'",1,warpstream,agent_deadscanner_optimistic_queue_delete_file_outcome,
warpstream.agent_deadscanner_optimistic_queue_submit_outcome,count,,,,"incremented whenever the Warpstream Agent submitted a request to the deadscanner optimistic queue, tagged by 'outcome'",1,warpstream,agent_deadscanner_optimistic_queue_submit_outcome,
warpstream.agent_deadscanner_outcomes,count,,,,"number of files processed by a deadscanner job execution, tagged by 'outcome'",1,warpstream,agent_deadscanner_outcomes,
warpstream.agent_file_cache_client_fetch_local_or_remote_counter,count,,,,"incremented whenever a Warpstream Agent loaded a file from its file cache, tagged by 'outcome' and 'source'",1,warpstream,agent_file_cache_client_fetch_local_or_remote_counter,
warpstream.agent_file_cache_client_fetch_local_or_remote_num_bytes_distribution,gauge,,byte,,"number of bytes loaded by a Warpstream Agent from its file cache, tagged by 'outcome' and 'source'",1,warpstream,agent_file_cache_client_fetch_local_or_remote_num_bytes_distribution,
warpstream.agent_file_cache_client_get_stream_range_latency,gauge,,second,,"latency to load a files to its cache from another Warpstream Agent, tagged by 'outcome'",-1,warpstream,agent_file_cache_client_get_stream_range_latency,
warpstream.agent_file_cache_client_get_stream_range_outcome,count,,,,"incremented for each request to load a file to its cache from another Warpstream Agent, tagged by 'outcome'",1,warpstream,agent_file_cache_client_get_stream_range_outcome,
warpstream.agent_file_cache_client_get_stream_range_partitioned_requests_counter,count,,,,"incremented by the number of partitioned requests to load a file to its cache from another Agent, tagged by 'outcome'",0,warpstream,agent_file_cache_client_get_stream_range_partitioned_requests_counter,
warpstream.agent_file_cache_client_get_stream_range_partitioned_requests_distribution,gauge,,,,"distribution flavor of 'warpstream.agent_file_cache_client_get_stream_range_partitioned_requests_counter'",-1,warpstream,agent_file_cache_client_get_stream_range_partitioned_requests_distribution,
warpstream.agent_file_cache_concurrent_fetches,count,,,,"incremented by 1 for each new request to fetch to a Warpstream Agent file cache",1,warpstream,agent_file_cache_concurrent_fetches,
warpstream.agent_file_cache_context_remaining_timeout,gauge,,second,,"timeout of a request to fetch to a Warpstream Agent file cache",-1,warpstream,agent_file_cache_context_remaining_timeout,
warpstream.agent_file_cache_get_range_num_chunks,gauge,,,,"number of chunks read in a given fetch request to a Warpstream Agent file cache",1,warpstream,agent_file_cache_get_range_num_chunks,
warpstream.agent_file_cache_server_blob_store_fetcher_counter,count,,,,"incremented by 1 every time a Warpstream Agent fetched data from the object storage to fill its file cache",1,warpstream,agent_file_cache_server_blob_store_fetcher_counter,
warpstream.agent_file_cache_server_blob_store_fetcher_num_bytes_counter,count,,byte,,"number of bytes fetched from the object storage to fill an Agent file cache",1,warpstream,agent_file_cache_server_blob_store_fetcher_num_bytes_counter,
warpstream.agent_file_cache_server_blob_store_fetcher_num_bytes_distribution,gauge,,byte,,"distribution of the number of bytes fetched from the object storage to fill an Agent file cache",0,warpstream,agent_file_cache_server_blob_store_fetcher_num_bytes_distribution,
warpstream.agent_file_cache_server_fetch_size_counter,count,,,,"incremented by 1 every time there is a cache miss and a Warpstream Agent needs to issue a GET to the object storage to fill its file cache",1,warpstream,agent_file_cache_server_fetch_size_counter,
warpstream.agent_file_cache_server_fetch_size_num_bytes_counter,count,,byte,,"number of bytes the Warpstream Agent had to GET from the object storage to fill its file cache because there is a cache miss",1,warpstream,agent_file_cache_server_fetch_size_num_bytes_counter,
warpstream.agent_file_cache_server_get_range_copy_chunk,count,,,,"incremented by 1 when a Warpstream Agent managed to read a chunk of data from its file cache",1,warpstream,agent_file_cache_server_get_range_copy_chunk,
warpstream.agent_file_cache_server_get_range_copy_chunk_num_bytes_copied,count,,byte,,"number of bytes copied from a Warpstream Agent file cache",1,warpstream,agent_file_cache_server_get_range_copy_chunk_num_bytes_copied,
warpstream.agent_file_cache_server_get_stream_range_latency,gauge,,second,,"latency of q request to read data from the object storage so an Agent can fill its file cache",-1,warpstream,agent_file_cache_server_get_stream_range_latency,
warpstream.agent_file_cache_server_get_stream_range_num_bytes_count,count,,byte,,"number of bytes read from the object storage so a Warpstream Agent can fill its file cache",1,warpstream,agent_file_cache_server_get_stream_range_num_bytes_count,
warpstream.agent_file_cache_server_get_stream_range_num_bytes_distribution,gauge,,byte,,"distribution of the number of bytes read from the object storage so an Agent can fill its file cache",0,warpstream,agent_file_cache_server_get_stream_range_num_bytes_distribution,
warpstream.agent_file_cache_server_get_stream_range_num_ranges_distribution,gauge,,,,"number of ranges fetched from the object storage so an Agent can fill its file cache",0,warpstream,agent_file_cache_server_get_stream_range_num_ranges_distribution,
warpstream.agent_file_cache_server_get_stream_range_outcome,count,,,,"incremented by 1 every time a Warpstream Agent has to fetch multiple ranges from the object object storage to fill its faile cache",1,warpstream,agent_file_cache_server_get_stream_range_outcome,
warpstream.agent_flushtuner_flush_size_rec,gauge,,byte,,"current value of the size autotuner used to flush data to the object storage when producing data",0,warpstream,agent_flushtuner_flush_size_rec,
warpstream.agent_job_runner_fetched_jobs_num_jobs,gauge,,,,"distribution of the number of jobs fetched when polling jobs from Warpstream control plane",1,warpstream,agent_job_runner_fetched_jobs_num_jobs,
warpstream.agent_job_runner_fetched_jobs_outcome,count,,,,"incremented by 1 every time a Warpstream Agent issued a poll request to the Warpstream control plane, tagged by 'outcome'",1,warpstream,agent_job_runner_fetched_jobs_outcome,
warpstream.agent_job_runner_no_jobs_found,count,,,,"incremented by 1 every time a Warpstream Agent issued a poll request to the Warpstream control plane and did not get any",1,warpstream,agent_job_runner_no_jobs_found,
warpstream.agent_job_runner_num_running_jobs_gauge,gauge,,,,"number of jobs currently running on a given Warpstream Agent",0,warpstream,agent_job_runner_num_running_jobs_gauge,
warpstream.agent_job_runner_num_running_slots_distribution,gauge,,,,"distribution of the job slots currently running on a given Warpstream Agent",0,warpstream,agent_job_runner_num_running_slots_distribution,
warpstream.agent_job_runner_num_running_slots_gauge,gauge,,,,"gauge of the job slots currently running on a given Warpstream Agent",0,warpstream,agent_job_runner_num_running_slots_gauge,
warpstream.agent_job_runner_slots_utilization_distribution,gauge,,,,"distribution of the ratio (between 0 and 1) of the job slots utilization",0,warpstream,agent_job_runner_slots_utilization_distribution,
warpstream.agent_job_runner_slots_utilization_gauge,gauge,,,,"distribution of the ratio (between 0 and 1) of the job slots utilization",0,warpstream,agent_job_runner_slots_utilization_gauge,
warpstream.agent_kafka_fetch_bytes_max,gauge,,byte,,"distribution of the max bytes of Kafka fetch requests issued to a Warpstream Agent",0,warpstream,agent_kafka_fetch_bytes_max,
warpstream.agent_kafka_fetch_bytes_min,gauge,,byte,,"distribution of the min bytes of Kafka fetch requests issued to a Warpstream Agent",0,warpstream,agent_kafka_fetch_bytes_min,
warpstream.agent_kafka_fetch_bytes_remaining,gauge,,byte,,"distribution of the number of bytes remaining when processing Kafka fetch requests issued to a Warpstream Agent",0,warpstream,agent_kafka_fetch_bytes_remaining,
warpstream.agent_kafka_fetch_compressed_bytes,gauge,,byte,,"distribution of the number of compressed bytes read when processing Kafka fetch requests issued to a Warpstream Agent",0,warpstream,agent_kafka_fetch_compressed_bytes,
warpstream.agent_kafka_fetch_compressed_bytes_counter,count,,byte,,"number of compressed bytes read when processing Kafka fetch requests issued on a Warpstream Agent",1,warpstream,agent_kafka_fetch_compressed_bytes_counter,
warpstream.agent_kafka_fetch_num_pointers_counter,count,,,,"number of pointers read when processing Kafka fetch requests issued to a Warpstream Agent",1,warpstream,agent_kafka_fetch_num_pointers_counter,
warpstream.agent_kafka_fetch_num_pointers_distribution,gauge,,,,"distribution of the number of pointers read when processing Kafka fetch requests issued to a Warpstream Agent",0,warpstream,agent_kafka_fetch_num_pointers_distribution,
warpstream.agent_kafka_fetch_partial_response_error_scenario_counter,count,,,,"number of partial fetch requests processed by a Warpstream Agent",1,warpstream,agent_kafka_fetch_partial_response_error_scenario_counter,
warpstream.agent_kafka_fetch_partial_response_error_scenario_num_bytes_distribution,gauge,,byte,,"distribution of the bytes in partial fetch requests processed by a Warpstream Agent",0,warpstream,agent_kafka_fetch_partial_response_error_scenario_num_bytes_distribution,
warpstream.agent_kafka_fetch_partitions_count,count,,,,"number of partitions read when processing Kafka fetch requests issued to a Warpstream Agent",1,warpstream,agent_kafka_fetch_partitions_count,
warpstream.agent_kafka_fetch_prefetch_concurrency_distribution,gauge,,,,"distribution of the concurrency used to prefetch data when processing Kafka fetch requests issued on an Agent",0,warpstream,agent_kafka_fetch_prefetch_concurrency_distribution,
warpstream.agent_kafka_fetch_request_latency,gauge,,second,,"latency of Kafka fetch requests issued to a Warpstream Agent",0,warpstream,agent_kafka_fetch_request_latency,
warpstream.agent_kafka_fetch_single_attempt_latency,gauge,,second,,"latency of a single attempt to process Kafka fetch requests issued to a Warpstream Agent",-1,warpstream,agent_kafka_fetch_single_attempt_latency,
warpstream.agent_kafka_fetch_single_attempt_outcome,count,,,,"number of attempts to process Kafka fetch requests issued to a Warpstream Agent",1,warpstream,agent_kafka_fetch_single_attempt_outcome,
warpstream.agent_kafka_fetch_topics_count,count,,,,"number of topics read when processing Kafka fetch requests issued to a Warpstream Agent",1,warpstream,agent_kafka_fetch_topics_count,
warpstream.agent_kafka_fetch_uncompressed_bytes,gauge,,byte,,"distribution of the number of uncompressed bytes read when processing Kafka fetch requests issued to an Agent",0,warpstream,agent_kafka_fetch_uncompressed_bytes,
warpstream.agent_kafka_fetch_uncompressed_bytes_counter,count,,byte,,"number of uncompressed bytes read when processing Kafka fetch requests issued on an Agent",1,warpstream,agent_kafka_fetch_uncompressed_bytes_counter,
warpstream.agent_kafka_inflight_connections,gauge,,,,"gauge of the number of inflight Kafka connections opened to a Warpstream Agent",0,warpstream,agent_kafka_inflight_connections,
warpstream.agent_kafka_inflight_request_per_connection,gauge,,,,"distribution of the number of requests per Kafka connections open to an Agent",0,warpstream,agent_kafka_inflight_request_per_connection,
warpstream.agent_kafka_inflight_request_per_connection_on_close,count,,,,"number of inflight requests when closing a connection",0,warpstream,agent_kafka_inflight_request_per_connection_on_close,
warpstream.agent_kafka_inflight_requests,gauge,,,,"gauge of the number of inflight Kafka requests issued to a Warpstream Agent",0,warpstream,agent_kafka_inflight_requests,
warpstream.agent_kafka_joingroup_poll_iterations,gauge,,,,"distribution of the number of iterations to poll when processing a Kafka JoinGroup request",0,warpstream,agent_kafka_joingroup_poll_iterations,
warpstream.agent_kafka_produce_compressed_bytes,gauge,,byte,,"distribution of the number of compressed bytes written when processing Kafka produce requests issued to an Agent",0,warpstream,agent_kafka_produce_compressed_bytes,
warpstream.agent_kafka_produce_compressed_bytes_counter,count,,byte,,"number of compressed bytes written when processing Kafka produce requests issued to a Warpstream Agent",1,warpstream,agent_kafka_produce_compressed_bytes_counter,
warpstream.agent_kafka_produce_uncompressed_bytes,gauge,,byte,,"distribution of the number of uncompressed bytes written when processing Kafka produce requests issued to an Agent",0,warpstream,agent_kafka_produce_uncompressed_bytes,
warpstream.agent_kafka_produce_uncompressed_bytes_counter,count,,byte,,"number of uncompressed bytes written when processing Kafka produce requests issued to a Warpstream Agent",0,warpstream,agent_kafka_produce_uncompressed_bytes_counter,
warpstream.agent_kafka_produce_with_offset_uncompressed_bytes,gauge,,byte,,"distribution of the number of uncompressed bytes written when processing Kafka produce with offset requests issued to an Agent",0,warpstream,agent_kafka_produce_with_offset_uncompressed_bytes,
warpstream.agent_kafka_produce_with_offset_uncompressed_bytes_counter,count,,byte,,"number of uncompressed bytes written when processing Kafka produce with offset requests issued to an Agent",1,warpstream,agent_kafka_produce_with_offset_uncompressed_bytes_counter,
warpstream.agent_kafka_request_count,count,,,,"number of Kafka requests processed by a Warpstream Agent",1,warpstream,agent_kafka_request_count,
warpstream.agent_kafka_request_latency,gauge,,second,,"latency of Kafka requests processed by an Agent at the connection level",0,warpstream,agent_kafka_request_latency,
warpstream.agent_kafka_request_outcome,count,,,,"number of Kafka requests processed by a Warpstream Agent tagged by 'outcome'",1,warpstream,agent_kafka_request_outcome,
warpstream.agent_kafka_request_process_latency,gauge,,second,,"latency to actually process a Kafka request by an Agent",0,warpstream,agent_kafka_request_process_latency,
warpstream.agent_kafka_source_cluster_connections_counter,count,,,,"number of connections opened from Orbit to a source cluster",1,warpstream,agent_kafka_source_cluster_connections_counter,
warpstream.agent_net_kafka_tcp_idle_conn_close,count,,,,"number of Kafka connections closed because it was idle",1,warpstream,agent_net_kafka_tcp_idle_conn_close,
warpstream.agent_net_kafka_tcp_limit_listener_acquire_count,count,,,,"number of times the Warpstream Agent accepted a new Kafka active connections",1,warpstream,agent_net_kafka_tcp_limit_listener_acquire_count,
warpstream.agent_net_kafka_tcp_limit_listener_acquire_latency,gauge,,second,,"latency to accept a new Kafka active connection",-1,warpstream,agent_net_kafka_tcp_limit_listener_acquire_latency,
warpstream.agent_produce_backpressure_count,count,,,,"incremented by 1 every time a Warpstream Agent backpressured a produce request, tagged by 'kafka_method' and 'backpressure_source'",1,warpstream,agent_produce_backpressure_count,
warpstream.agent_produce_outcome,count,,,,"incremented every time a produce request has been processed, tagged by 'outcome'",1,warpstream,agent_produce_outcome,
warpstream.agent_run_and_ack_job_latency,gauge,,second,,"latency to run a job and acknowledge it back to Warpstream control plane",-1,warpstream,agent_run_and_ack_job_latency,
warpstream.agent_run_and_ack_job_outcome,count,,,,"incremented by 1 every time a job has been run and acknowledged, tagged by 'outcome'",1,warpstream,agent_run_and_ack_job_outcome,
warpstream.agent_segment_batcher_flush_file_size_compressed_bytes,gauge,,byte,,"distribution of the compressed size of files batched in-memory before flushing to the object storage when processing a produce request",0,warpstream,agent_segment_batcher_flush_file_size_compressed_bytes,
warpstream.agent_segment_batcher_flush_file_size_uncompressed_bytes,gauge,,byte,,"distribution of the uncompressed size of files batched in-memory before flushing to the object storage when processing a produce request",0,warpstream,agent_segment_batcher_flush_file_size_uncompressed_bytes,
warpstream.agent_segment_batcher_flush_new_file_duration,gauge,,second,,"distribution of the latency to batch in-memory before flushing to the object storage when processing a produce request",-1,warpstream,agent_segment_batcher_flush_new_file_duration,
warpstream.agent_segment_batcher_flush_num_batches,count,,,,"counter of batches in a file flushed to object storage",1,warpstream,agent_segment_batcher_flush_num_batches,
warpstream.agent_segment_batcher_flush_num_records_counter,count,,,,"counter of records in a file flushed to object storage",1,warpstream,agent_segment_batcher_flush_num_records_counter,
warpstream.agent_segment_batcher_flush_num_records_distribution,gauge,,,,"distribution of the number of records in a file flushed to object storage",0,warpstream,agent_segment_batcher_flush_num_records_distribution,
warpstream.agent_segment_batcher_flush_outcome,count,,,,"incremented by 1 every time the Warpstream Agent flushed a file to the object storage, tagged by 'outcome'",0,warpstream,agent_segment_batcher_flush_outcome,
warpstream.agent_segment_batcher_flush_put_file_duration,gauge,,second,,"latency to advertise a new file to Warpstream control plane",-1,warpstream,agent_segment_batcher_flush_put_file_duration,
warpstream.agent_segment_batcher_flush_total_duration,gauge,,second,,"total time to flush a file and advertise it to Warpstream control plane",-1,warpstream,agent_segment_batcher_flush_total_duration,
warpstream.agent_segment_batcher_flush_write_to_duration,gauge,,second,,"time to upload a new file to object storage",-1,warpstream,agent_segment_batcher_flush_write_to_duration,
warpstream.blob_store_get_stream_range_num_bytes_distribution,gauge,,byte,,"latency of the number of bytes read from object storage when reading ranges from a stream",0,warpstream,blob_store_get_stream_range_num_bytes_distribution,
warpstream.blob_store_operation_latency,gauge,,second,,"distribution of the latency of requests to object storage, tagged by 'operation'",-1,warpstream,blob_store_operation_latency,
warpstream.build_age_unix_ms,gauge,,millisecond,,"time since the Warpstream Agent binary was built",1,warpstream,build_age_unix_ms,
warpstream.circuit_breaker_count,count,,,,"incremented every time every time a circuit breaker state changes, tagged by 'name' and 'state'",1,warpstream,circuit_breaker_count,
warpstream.circuit_breaker_hits,count,,,,"incremented every time a circuit breaker records a success or a failure, tagged by 'name' and 'outcome'",1,warpstream,circuit_breaker_hits,
warpstream.circuit_breaker_permit,count,,,,"incremented every time the Warpstream Agent tried to get a permit from a circuit breaker, tagged by 'name' and 'outcome'",1,warpstream,circuit_breaker_permit,
warpstream.circuit_breaker_state_set,gauge,,,,"gauge of a circuit breaker state, tagged by 'name' and 'state'",0,warpstream,circuit_breaker_state_set,
warpstream.consumer_group_estimated_lag_very_coarse_do_not_use_to_measure_e2e_seconds,gauge,,second,,"consumer time lag estimate, its tagging depends on the Warpstream Agent settings",-1,warpstream,consumer_group_estimated_lag_very_coarse_do_not_use_to_measure_e2e_seconds,
warpstream.consumer_group_generation_id,gauge,,,,"indicates the generation number of the consumer group, incrementing by one with each rebalance. It serves as an effective indicator for detecting occurrences of rebalances.",0,warpstream,consumer_group_generation_id,
warpstream.consumer_group_lag,gauge,,,,"sum of the consumer group lag across the topic's partitions",0,warpstream,consumer_group_lag,
warpstream.consumer_group_num_members,gauge,,,,"number of members in each consumer group",0,warpstream,consumer_group_num_members,
warpstream.consumer_group_num_partitions,gauge,,,,"number of partitions in each consumer group",0,warpstream,consumer_group_num_partitions,
warpstream.consumer_group_num_topics,gauge,,,,"number of topics in each consumer group",0,warpstream,consumer_group_num_topics,
warpstream.consumer_group_state,gauge,,,,"indicates state of consumer group, tagged by 'consumer_group' and 'group_state'",0,warpstream,consumer_group_state,
warpstream.container_running,gauge,,,,"gauge set to 1 by each Warpstream Agent running",0,warpstream,container_running,
warpstream.cpu_utilization_go_runtime,gauge,,percent,,"current process's CPU utilization from the go runtime's perspective",0,warpstream,cpu_utilization_go_runtime,
warpstream.cpu_utilization_os,gauge,,percent,,"current process's CPU utilization from the operating system's perspective",0,warpstream,cpu_utilization_os,
warpstream.diagnostic_status,gauge,,,,"diagnostic status, tagged by 'diagnostic_name', 'diagnostic_type', 'successful' and 'muted'. This metric is deprecated, you should use 'diagnostic_failure' instead.",0,warpstream,diagnostic_status,
warpstream.error_count,count,,,,"number of error logs",0,warpstream,error_count,
warpstream.fast_retrier_execution,count,,,,"number of times the fast retrier was used",1,warpstream,fast_retrier_execution,
warpstream.fast_retrier_p99_ms,gauge,,millisecond,,"p99 latency tracked by a fast retrier",-1,warpstream,fast_retrier_p99_ms,
warpstream.fast_retrier_speculative_retry,count,,,,"number of times a fast retrier interrupted an ongoing request to retry it faster",1,warpstream,fast_retrier_speculative_retry,
warpstream.file_cache_batcher_batches_count,count,,,,"number of batches to the file cache",1,warpstream,file_cache_batcher_batches_count,
warpstream.file_cache_batcher_batches_distribution,gauge,,,,"distribution of the number of batches to the file cache",0,warpstream,file_cache_batcher_batches_distribution,
warpstream.file_cache_batcher_called,count,,,,"number of times a Warpstream Agent batched requests to the file cache",1,warpstream,file_cache_batcher_called,
warpstream.files_count,gauge,,,,"number of files tracked by Warpstream control planed, tagged by 'level' of compaction",0,warpstream,files_count,
warpstream.get_records_batch_batches_count,count,,,,"number of batches when issuing a GetRecords request to Warpstream control plane",1,warpstream,get_records_batch_batches_count,
warpstream.get_records_batch_batches_distribution,gauge,,,,"distribution of number of batches when issuing a GetRecords request to Warpstream control plane",0,warpstream,get_records_batch_batches_distribution,
warpstream.get_records_batch_called,count,,,,"number of times a Warpstream Agent batched GetRecords requests",1,warpstream,get_records_batch_called,
warpstream.global_ratelimit_fetch_compressed_bytes,count,,byte,,"number of fetch request bytes rate limited",0,warpstream,global_ratelimit_fetch_compressed_bytes,
warpstream.kafka_batcher_batches_count,count,,,,"number of batches when issuing Kafka requests (not produce nor fetch) to Warpstream control plane",1,warpstream,kafka_batcher_batches_count,
warpstream.kafka_batcher_batches_distribution,gauge,,,,"distribution of number of batches when issuing Kafka requests (not produce nor fetch) to Warpstream control plane",0,warpstream,kafka_batcher_batches_distribution,
warpstream.kafka_batcher_called,count,,,,"number of times a Warpstream Agent processed a Kafka request (not produce nor fetch)",1,warpstream,kafka_batcher_called,
warpstream.list_streams_batcher_batches_count,count,,,,"number of batches when issuing a ListStream request to Warpstream control plane",1,warpstream,list_streams_batcher_batches_count,
warpstream.list_streams_batcher_batches_distribution,gauge,,,,"distribution of the number of batches when issuing a ListStream request to Warpstream control plane",0,warpstream,list_streams_batcher_batches_distribution,
warpstream.list_streams_batcher_called,count,,,,"number of times an Agent a ListStream request",1,warpstream,list_streams_batcher_called,
warpstream.loading_cache_loader_outcome,count,,,,"incremented by 1 every time a loading cache filled a key, tagged by 'cache_name' and 'outcome'",0,warpstream,loading_cache_loader_outcome,
warpstream.loading_cache_refresh_completed,count,,,,"incremented by 1 every time a loading cache refreshed a key, tagged by 'cache_name' and 'outcome'",0,warpstream,loading_cache_refresh_completed,
warpstream.max_offset,gauge,,,,"max Kafka offset",0,warpstream,max_offset,
warpstream.net_http_tcp_limit_listener_acquire_count,count,,,,"number of times the Warpstream Agent accepted a new HTTP active connection",0,warpstream,net_http_tcp_limit_listener_acquire_count,
warpstream.net_http_tcp_limit_listener_acquire_latency,gauge,,second,,"latency to accept a new HTTP active connection",-1,warpstream,net_http_tcp_limit_listener_acquire_latency,
warpstream.num_records,gauge,,,,"number of records",0,warpstream,num_records,
warpstream.partitions_count,gauge,,,,"number of partitions",0,warpstream,partitions_count,
warpstream.partitions_count_limit,gauge,,,,"max number of partitions",0,warpstream,partitions_count_limit,
warpstream.schema_versions_count,gauge,,,,"number of schema registry versions",0,warpstream,schema_versions_count,
warpstream.schema_versions_limit,gauge,,,,"max number of schema registry versions",0,warpstream,schema_versions_limit,
warpstream.server_starting,count,,,,"incremented by 1 when a Warpstream Agent process starts",1,warpstream,server_starting,
warpstream.server_tick_running,count,,,,"incremented by 1 when a Warpstream Agent server tick ran",1,warpstream,server_tick_running,
warpstream.target_release_server_middleware,count,,,,"incremented by 1 when a Warpstream Agent check that a HTTP request was intended for this Warpstream cluster, tagged by 'outcome'",1,warpstream,target_release_server_middleware,
warpstream.topics_count,gauge,,,,"number of topics",0,warpstream,topics_count,
warpstream.topics_count_limit,gauge,,,,"max number of topics",0,warpstream,topics_count_limit,
warpstream.agent_ripcord_delete_file,count,,,,"number of files deleted by the ripcord replay job",1,warpstream,agent_ripcord_delete_file,
warpstream.agent_ripcord_replayed_file,count,,,,"number of files replayed by the ripcord replay job",1,warpstream,agent_ripcord_replayed_file,
warpstream.query_engine_active_queries_count,gauge,,,,"number of active queries being currently processed by the query engine",0,warpstream,query_engine_active_queries_count,
warpstream.diagnostic_failure,gauge,,,,"diagnostic failures, tagged by 'diagnostic_name', 'diagnostic_type', 'severity_low', 'severity_medium', 'severity_high', 'muted'",0,warpstream,diagnostic_failure,
warpstream.events_processor_produce_success_count,count,,,,"number of events successfully produced",1,warpstream,events_processor_produce_success_count,
warpstream.events_processor_produce_error_count,count,,,,"number of events failed to produce",1,warpstream,events_processor_produce_error_count,
warpstream.events_processor_submit_bytes_count,count,,,,"number of event bytes successfully submitted",1,warpstream,events_processor_submit_bytes_count,
warpstream.events_processor_submit_success_count,count,,,,"number of event successfully submitted",1,warpstream,events_processor_submit_success_count,
warpstream.orbit_handler_num_fetches,count,,,,"incremented by 1 every time Orbit issues a fetch request to the source cluster",1,warpstream,orbit_handler_num_fetches,
warpstream.orbit_handler_num_polls,count,,,,"incremented by 1 every time Orbit does a fetch followed by a produce",1,warpstream,orbit_handler_num_polls,
warpstream.orbit_handler_bytes_fetched_during_poll,count,,,,"number of bytes fetched during a fetch and produce loop",1,warpstream,orbit_handler_bytes_fetched_during_poll,
warpstream.orbit_handler_bytes_in_fetch,count,,,,"incremented for each byte fetched from the source cluster",1,warpstream,orbit_handler_bytes_in_fetch,
warpstream.agent_kafka_fetch_num_pointers_counter_by_level,count,,,,"number of pointers read when processing Kafka fetch requests issued to a Warpstream Agent tagged by `compaction_level`",1,warpstream,agent_kafka_fetch_num_pointers_counter_by_level,
warpstream.agent_kafka_fetch_num_pointers_distribution_by_level,gauge,,,,"distribution of the number of pointers read when processing Kafka fetch requests issued to a Warpstream Agent tagged by `compaction_level`",0,warpstream,agent_kafka_fetch_num_pointers_distribution_by_level,
warpstream.agent_control_plane_operation_latency,gauge,,second,,"latency of requests made to WarpStream control plane",-1,warpstream,agent_control_plane_operation_latency,
warpstream.agent_kafka_produce_records_counter,count,,,,"number of events successfully produced",1,warpstream,agent_kafka_produce_records_counter,
warpstream.agent_ripcord_deleted_file_queue,gauge,,second,,"latency between the time a file was queued for deletion and it actually got removed",-1,warpstream,agent_ripcord_deleted_file_queue,
warpstream.loading_cache_refresh_throttled,count,,,,"incremented by 1 every time an in-memory cache throttles a refresh request",1,warpstream,loading_cache_refresh_throttled,
warpstream.agent_kafka_connection_state_cache_outcome,count,,,,"incremented by 1 when we read from a Kafka connection cache, tagged by `outcome`",1,warpstream,agent_kafka_connection_state_cache_outcome,
warpstream.logs_async_queue_push_count,count,,,,"incremented by 1 when a log is submitted to the async logger",1,warpstream,logs_async_queue_push_count,
warpstream.node_heartbeat,count,,,,"incremented by 1 when a WarpStream agent emits a heartbeat, tagged by `outcome` and `mechanism`",1,warpstream,node_heartbeat,
warpstream.single_value_cache_loader_outcome,count,,,,"incremented by 1 when we successfully load a value from a single value cache",1,warpstream,single_value_cache_loader_outcome,
warpstream.agent_kafka_fetch_request_num_top_level_fetch_had_no_pointers_in_a_row,gauge,,,,"distribution of the number of fetches that did not retrieve any data consecutively",0,warpstream,agent_kafka_fetch_request_num_top_level_fetch_had_no_pointers_in_a_row,
warpstream.agent_segment_batcher_flush_to_start_commit_duration,gauge,,second,,"distribution of the latency to batch in-memory before committing the new files to the WarpStream control plane",-1,warpstream,agent_segment_batcher_flush_to_start_commit_duration,
warpstream.embedded_node_pool_tracker_refresh_by_mechanism_agent,count,,,,"incremented by 1 every time the service discovery refreshes `mechanism`",1,warpstream,embedded_node_pool_tracker_refresh_by_mechanism_agent,
warpstream.logs_async_queue_size_bytes,gauge,,byte,,"number of bytes in the async logger queue",1,warpstream,logs_async_queue_size_bytes,
warpstream.control_plane_utilization,gauge,,,,"value between 0 and 1 to represent the utilization of the control plane for the virtual cluster. Getting close to 1 means that the control plane will start throttling requests.",0,warpstream,control_plane_utilization,
warpstream.agent_control_plane_operation_counter,count,,,,"incremented by 1 every time an agent issues a HTTP request to the control plane",1,warpstream,agent_control_plane_operation_counter,
warpstream.agent_kafka_fetch_records_counter,count,,,,"counts the number of records present in all of the data pages the agent fetched to respond to fetches.",1,warpstream,agent_kafka_fetch_records_counter,
warpstream.consistent_assignments_cache_invalidation,count,,,,"counts the number times an agent had to invalidate one of its metadata cache",1,warpstream,consistent_assignments_cache_invalidation,
warpstream.agent_kafka_metadata_preserve_previous_partition_assignments,count,,,,"counts the number of times we were able to re-use a previous partition assignment while handling a metadata request tagged by `outcome`",1,warpstream,agent_kafka_metadata_preserve_previous_partition_assignments,
warpstream.agent_kafka_request_latency_before_response,gauge,,second,,"latency to process a Kafka request before starting to write the response in the TCP socket tagged by `outcome`",-1,warpstream,agent_kafka_request_latency_before_response,
warpstream.query_engine_runnable_tasks_count,gauge,,,,"distribution of the number of runnable tasks in the query engine",0,warpstream,query_engine_runnable_tasks_count,
warpstream.schema_validation_invalid_record_count,count,,,,"counts the number of invalid records found during schema validation",1,warpstream,schema_validation_invalid_record_count,
warpstream.logs_forwarder_error,count,,,,"counts the number of errors while trying to forward logs to the WarpStream control plane",1,warpstream,logs_forwarder_error,
warpstream.agent_ripcord_ingestion_latency,gauge,,second,,"latency to ingest data in lightning topics or ripcord mode",-1,warpstream,agent_ripcord_ingestion_latency,
warpstream.query_engine_queue_runnable_task,count,,,,"counts the number of runnable tasks we enqueued in the query engine",1,warpstream,query_engine_queue_runnable_task,
warpstream.query_engine_query_started,count,,,,"counts the number of queries the query engine has started to process",1,warpstream,query_engine_query_started,
warpstream.query_engine_exec_task,count,,,,"counts the number of tasks being executed by the query engine",1,warpstream,query_engine_exec_task,
warpstream.query_engine_task_completed_count,count,,,,"counts the number of tasks completed by the query engine tagged by `outcome`",1,warpstream,query_engine_task_completed_count,
warpstream.query_engine_task_completed_duration,gauge,,second,,"latency of task completion in the query engine tagged by `outcome`",-1,warpstream,query_engine_task_completed_duration,
warpstream.agent_schema_registry_response_bytes_counter,count,,byte,,"counts the number of bytes of schema registry responses tagged by `outcome` and `operation`",1,warpstream,agent_schema_registry_response_bytes_counter,
warpstream.schema_linking_source_subject_versions_count,gauge,,,,"total number of subject versions synced by schema linking tagged by `sync_id` and `config_id`",-1,warpstream,schema_linking_source_subject_versions_count,
warpstream.schema_linking_newly_migrated_subject_versions,gauge,,,,"number of subject versions just migrated by schema linking tagged by `sync_id` and `config_id`",-1,warpstream,schema_linking_newly_migrated_subject_versions,
warpstream.agent_schema_registry_inflight_connections,gauge,,,,"gauge of the number of inflight Schema Registry connections opened to a Warpstream Agent",0,warpstream,agent_schema_registry_inflight_connections,
warpstream.agent_schema_registry_request_bytes_counter,count,,byte,,"number of uncompressed bytes read when processing Schema Registry fetch requests issued on an Agent",1,warpstream,agent_schema_registry_request_bytes_counter,
warpstream.agent_schema_registry_request_latency,gauge,,second,,"latency of Schema Registry fetch requests issued to a Warpstream Agent",0,warpstream,agent_schema_registry_request_latency,
warpstream.agent_schema_registry_request_outcome,count,,,,"number of Schema Registry requests processed by a Warpstream Agent tagged by 'outcome'",1,warpstream,agent_schema_registry_request_outcome,
warpstream.tableflow_snapshots_limit,gauge,,,,"max number of Tableflow snapshots on a given cluster",0,warpstream,tableflow_snapshots_limit,
warpstream.tableflow_tables_limit,gauge,,,,"max number of Tableflow tables on a given cluster",0,warpstream,tableflow_tables_limit,
warpstream.tableflow_files_limit,gauge,,,,"max number of Tableflow files on a given cluster",0,warpstream,tableflow_files_limit,
warpstream.agent_tableflow_files_written,count,,,,"counts the number of files written by Tableflow agents",1,warpstream,agent_tableflow_files_written,
warpstream.ingestion_job_kafka_time_lag_ms,gauge,,millisecond,,"time lag of the Tableflow ingestion job that is consuming from Kafka and producing Tableflow files - this is deprecated please use `warpstream.tableflow_partition_time_lag_seconds",1,warpstream,ingestion_job_kafka_time_lag_ms,
warpstream.ingestion_job_dlq_skip_strategy_counter,count,,,,"counts the number of records that were skipped during Tableflow ingestion while using the skip strategy tagged by `topic`",1,warpstream,ingestion_job_dlq_skip_strategy_counter,
warpstream.tableflow_tables_count,count,,,,"counts the number of Tableflow tables created by WarpStream Agents",0,warpstream,tableflow_tables_count,
warpstream.tableflow_snapshots_count,count,,,,"counts the number of Tableflow snapshots created by Warpstream Agents",0,warpstream,tableflow_snapshots_count,
warpstream.tableflow_files_count,count,,,,"counts the number of Tableflow files created by WarpStream Agents",0,warpstream,tableflow_files_count,
warpstream.tableflow_partition_time_lag_seconds,gauge,,second,,"time lag of the Tableflow ingestion job that is consuming from Kafka and producing Tableflow files",1,warpstream,tableflow_partition_time_lag_seconds,
warpstream.agent_file_cache_too_many_concurrent_fetches,count,,,,"counts the number of times a Warpstream Agent filecache had to backpressure because there were too many concurrent fetches in parallel",0,warpstream,agent_file_cache_too_many_concurrent_fetches,
warpstream.agent_tableflow_bytes_written,count,,byte,,"number of bytes written by WarpStream agents while ingesting from Kafka to Tableflow tagged by `source_topic`",1,warpstream,agent_tableflow_bytes_written,
