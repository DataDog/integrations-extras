id: aimon
tests:
  - sample: >-
      {
      	"id": "AwAAAZbVgCvIFsFWSAAAABhBWmJWZ0RBWkFBQXNWc2c2RUx1MG5RQUEAAAAkMDE5NmQ1ODAtMmJjOC00MzM4LTgxNDMtMTZhNTZmZjE2YzM5AAAAAA",
      	"content": {
      		"timestamp": "2025-05-15T19:51:09Z",
      		"tags": [
      			"source:aimon",
      			"datadog.submission_auth:api_key"
      		],
      		"service": "aimon",
      		"message": "Response Evaluation",
      		"attributes": {
      			"request": "Summarize the key advancements mentioned in the article.",
      			"company_id": "ea58e3af-cb9c-4571-83fb-40b8c9d7803e",
      			"service": "aimon",
      			"output_safety": {
      				"toxicity": 0.6666666666666666
      			},
      			"version": 0,
      			"application_id": 325,
      			"output_quality": {
      				"conciseness": 0.2,
      				"context_classification": 0,
      				"hallucination": 0.99609375,
      				"instruction_adherence": 0.5,
      				"completeness": 0.25
      			},
      			"status": "info",
      			"timestamp": 1747338669000
      		}
      	}
      }
    result: null

# The `result` field should be left blank to start. Once you submit your log asset files with
# your integration pull-request in a Datadog GitHub repository, Datadog's validations will
# run your raw logs against your pipeline and return the result. If the result output in the
# validation is accurate, take the output and add it to the `result` field in your test YAML file.