metric_name,metric_type,description,orientation,integration,short_name,sample_tags
aimon.hallucination,gauge,Detects factual inaccuracies or fabricated content in LLM responses to help identify hallucinated information,-1,aimon,hallucination,"version,company_id,application_id"
aimon.conciseness,gauge,Evaluates whether the LLM output is succinct and avoids unnecessary verbosity while maintaining clarity,1,aimon,conciseness,"version,company_id,application_id"
aimon.completeness,gauge,Determines whether the LLM response fully and adequately addresses all components of the input query,1,aimon,completeness,"version,company_id,application_id"
aimon.toxicity,gauge,Identifies the presence of toxic offensive or harmful language in the LLM output to ensure safety and appropriateness,-1,aimon,toxicity,"version,company_id,application_id"
aimon.retrieval_relevance,gauge,Measures the relevance of retrieved context to the input query with support for domain-adaptable re-ranking,1,aimon,retrieval_relevance,"version,company_id,application_id"
aimon.context_classification,gauge,Classifies whether provided context was appropriately used in the LLM response and if it aligns with the user intent,1,aimon,context_classification,"version,company_id,application_id"
aimon.instruction_adherence,gauge,Measures how well the LLM response follows explicit instructions or task prompts ensuring alignment with user intent,1,aimon,instruction_adherence,"version,company_id,application_id"
aimon.health_check,gauge,Indicates the operational health of the AIMon evaluation pipeline and confirms that metric reporting is functioning,0,aimon,health_check,"version,company_id,application_id"
aimon.output_relevance,gauge,Measures how well the LLM response aligns with the user's query and ensures the output is pertinent and on topic,1,aimon,output_relevance,"version,company_id,application_id"

