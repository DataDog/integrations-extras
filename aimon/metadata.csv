metric_name,metric_type,interval,unit_name,per_unit_name,description,orientation,integration,short_name,curated_metric,sample_tags
aimon.groundedness,gauge,60,PERCENTAGE,,Detects fabricated or inaccurate content in LLM responses,1,aimon,groundedness,,"version,company_id,application_id"
aimon.conciseness,gauge,60,PERCENTAGE,,Evaluates whether the LLM output is succinct and clear,1,aimon,conciseness,,"version,company_id,application_id"
aimon.completeness,gauge,60,PERCENTAGE,,Determines whether the response fully answers the input query,1,aimon,completeness,,"version,company_id,application_id"
aimon.toxicity,gauge,60,PERCENTAGE,,"Identifies toxic or harmful language in the LLM output",1,aimon,toxicity,,"version,company_id,application_id"
aimon.retrieval_relevance,gauge,60,PERCENTAGE,,Measures how relevant the retrieved context is to the query,1,aimon,retrieval_relevance,,"version,company_id,application_id"
aimon.context_classification,gauge,60,PERCENTAGE,,Classifies whether the provided context was used appropriately and aligns with user intent,1,aimon,context_classification,,"version,company_id,application_id"
aimon.instruction_adherence,gauge,60,PERCENTAGE,,Measures how well the instructions are followed while generating a response,1,aimon,instruction_adherence,,"version,company_id,application_id"
aimon.health_check,gauge,60,PERCENTAGE,,Indicates whether AIMon is reporting metrics correctly,0,aimon,health_check,,"version,company_id,application_id"
aimon.output_relevance,gauge,60,PERCENTAGE,,Measures how well the response aligns with the user query,1,aimon,output_relevance,,"version,company_id,application_id"
aimon.prompt_injection,gauge,60,PERCENTAGE,,Detects attempts in the user query to override system instructions using adversarial language,1,aimon,prompt_injection,,"version,company_id,application_id"
aimon.cbrn,gauge,60,PERCENTAGE,,"Flags model outputs that include references to chemical, biological, radiological, or nuclear threats or related instructions",1,aimon,cbrn,,"version,company_id,application_id"
aimon.personal_harm,gauge,60,PERCENTAGE,,"Detects mentions of self-harm, suicide, or encouragement of physically dangerous behavior in the model's output",1,aimon,personal_harm,,"version,company_id,application_id"
aimon.unsafe_stereotypes,gauge,60,PERCENTAGE,,"Detects biased or discriminatory content in model outputs based on race, gender, religion, or identity groups",1,aimon,unsafe_stereotypes,,"version,company_id,application_id"
aimon.code_detection,gauge,60,PERCENTAGE,,Detects unsafe or system-level code patterns in the user query to prevent unintended execution or exploitation,1,aimon,code_detection,,"version,company_id,application_id"
aimon.sql_prevention,gauge,60,PERCENTAGE,,Flags SQL keywords or injection patterns in the user query that may indicate data access attempts or prompt attacks,1,aimon,sql_prevention,,"version,company_id,application_id"
aimon.jailbreak,gauge,60,PERCENTAGE,,Identifies jailbreak tactics in the user query designed to elicit harmful or filtered responses from the model,1,aimon,jailbreak,,"version,company_id,application_id"
aimon.pii,gauge,60,PERCENTAGE,,"Flags exposure of personally identifiable information such as names, addresses, or contact details in the model's output",1,aimon,pii,,"version,company_id,application_id"
